#!/usr/bin/env python3
"""
Test script for the new advanced bias analysis implementation.
This script tests the integration of SliceFinder, TensorFlow Model Analysis, and Fairlearn.
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime

# Add the scripts directory to the path
sys.path.append(os.path.join(os.path.dirname(__file__), 'scripts', 'data_preprocessing'))

from schema_statistics import SchemaStatisticsManager

def create_test_data():
    """Create synthetic test data for bias analysis."""
    np.random.seed(42)
    n_samples = 1000
    
    # Create synthetic medical data with intentional biases
    data = {
        'Patient_ID': range(n_samples),
        'Gender': np.random.choice(['Male', 'Female', 'Other'], n_samples, p=[0.6, 0.35, 0.05]),
        'Age_Years': np.random.normal(50, 15, n_samples).astype(int),
        'Weight_KG': np.random.normal(70, 15, n_samples),
        'Height_CM': np.random.normal(170, 10, n_samples),
        'Urgency_Level': np.random.choice(['Routine', 'Urgent', 'Emergent', 'STAT'], n_samples, p=[0.5, 0.3, 0.15, 0.05]),
        'Body_Region': np.random.choice(['Head', 'Chest', 'Abdomen', 'Pelvis', 'Extremities'], n_samples, p=[0.2, 0.3, 0.2, 0.15, 0.15])
    }
    
    # Create biased diagnosis based on gender and age
    diagnosis = []
    for i in range(n_samples):
        gender = data['Gender'][i]
        age = data['Age_Years'][i]
        
        # Introduce bias: females and elderly more likely to have certain conditions
        if gender == 'Female' and age > 60:
            diagnosis.append(np.random.choice(['Normal', 'TB', 'Cancer'], p=[0.3, 0.4, 0.3]))
        elif gender == 'Male' and age < 40:
            diagnosis.append(np.random.choice(['Normal', 'TB', 'Cancer'], p=[0.6, 0.3, 0.1]))
        else:
            diagnosis.append(np.random.choice(['Normal', 'TB', 'Cancer'], p=[0.5, 0.3, 0.2]))
    
    data['Diagnosis_Class'] = diagnosis
    
    return pd.DataFrame(data)

def test_advanced_bias_analysis():
    """Test the advanced bias analysis implementation."""
    print("ðŸ§ª Testing Advanced Bias Analysis Implementation")
    print("=" * 60)
    
    # Create test data
    print("ðŸ“Š Creating synthetic test data with intentional biases...")
    df = create_test_data()
    print(f"   Created {len(df)} samples")
    print(f"   Gender distribution: {df['Gender'].value_counts().to_dict()}")
    print(f"   Diagnosis distribution: {df['Diagnosis_Class'].value_counts().to_dict()}")
    
    # Initialize SchemaStatisticsManager
    print("\nðŸ”§ Initializing SchemaStatisticsManager...")
    try:
        manager = SchemaStatisticsManager()
        print("   âœ… SchemaStatisticsManager initialized successfully")
    except Exception as e:
        print(f"   âŒ Failed to initialize SchemaStatisticsManager: {e}")
        return False
    
    # Test bias detection
    print("\nðŸ” Running advanced bias detection...")
    output_path = "test_bias_analysis.json"
    
    try:
        bias_results = manager.detect_bias_via_slicing(
            dataset_name="test_synthetic_data",
            df=df,
            output_path=output_path
        )
        
        if bias_results is None:
            print("   âš ï¸ Bias detection returned None (may be disabled in config)")
            return True
        
        print("   âœ… Bias analysis completed successfully")
        
        # Display results
        print(f"\nðŸ“‹ Analysis Results:")
        print(f"   Libraries used: {bias_results.get('libraries_used', [])}")
        print(f"   Bias detected: {bias_results.get('bias_detected', False)}")
        print(f"   Problematic slices: {len(bias_results.get('problematic_slices', []))}")
        print(f"   Significant biases: {len(bias_results.get('significant_biases', []))}")
        
        # Show recommendations
        recommendations = bias_results.get('recommendations', [])
        if recommendations:
            print(f"\nðŸ’¡ Recommendations:")
            for i, rec in enumerate(recommendations[:5], 1):  # Show first 5
                print(f"   {i}. {rec}")
        
        # Show library-specific results
        if 'slicefinder_analysis' in bias_results:
            sf_results = bias_results['slicefinder_analysis']
            if 'error' not in sf_results:
                print(f"\nðŸ” SliceFinder Results:")
                print(f"   Problematic slices found: {sf_results.get('num_problematic_slices', 0)}")
            else:
                print(f"\nðŸ” SliceFinder: {sf_results['error']}")
        
        if 'tfma_analysis' in bias_results:
            tfma_results = bias_results['tfma_analysis']
            if 'error' not in tfma_results:
                print(f"\nðŸ“Š TFMA Results:")
                print(f"   Bias detected: {tfma_results.get('bias_detected', False)}")
                print(f"   Overall accuracy: {tfma_results.get('overall_accuracy', 0):.3f}")
            else:
                print(f"\nðŸ“Š TFMA: {tfma_results['error']}")
        
        if 'fairlearn_analysis' in bias_results:
            fl_results = bias_results['fairlearn_analysis']
            if 'error' not in fl_results:
                print(f"\nâš–ï¸ Fairlearn Results:")
                print(f"   Bias detected: {fl_results.get('bias_detected', False)}")
                fairness_metrics = fl_results.get('fairness_metrics', {})
                if 'demographic_parity' in fairness_metrics:
                    dp = fairness_metrics['demographic_parity']
                    if 'error' not in dp:
                        print(f"   Demographic parity difference: {dp.get('difference', 0):.3f}")
            else:
                print(f"\nâš–ï¸ Fairlearn: {fl_results['error']}")
        
        return True
        
    except Exception as e:
        print(f"   âŒ Bias detection failed: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """Main test function."""
    print("ðŸš€ Advanced Bias Analysis Test Suite")
    print("=" * 60)
    print(f"Timestamp: {datetime.now().isoformat()}")
    print()
    
    # Test the implementation
    success = test_advanced_bias_analysis()
    
    print("\n" + "=" * 60)
    if success:
        print("âœ… All tests passed! Advanced bias analysis is working correctly.")
        print("\nðŸ“š Libraries integrated:")
        print("   â€¢ Custom SliceFinder: Automatic problematic slice discovery")
        print("   â€¢ TensorFlow Model Analysis: Comprehensive model performance slicing")
        print("   â€¢ Fairlearn: Industry-standard fairness metrics")
    else:
        print("âŒ Some tests failed. Check the error messages above.")
    
    return success

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)
